<?xml version="1.0"?>
<!--
  JBoss, Home of Professional Open Source
  Copyright 2008, Red Hat Middleware LLC, and individual contributors
  as indicated by the @author tags.
  See the copyright.txt in the distribution for a
  full listing of individual contributors.
  This copyrighted material is made available to anyone wishing to use,
  modify, copy, or redistribute it subject to the terms and conditions
  of the GNU Lesser General Public License, v. 2.1.
  This program is distributed in the hope that it will be useful, but WITHOUT A
  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  You should have received a copy of the GNU Lesser General Public License,
  v.2.1 along with this distribution; if not, write to the Free Software
  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  MA  02110-1301, USA.

  (C) 2008,
  @author JBoss Inc.
-->
<!--
  Ant build script for running QA tests using junit.

  For JBossTS JTS builds.

  1) Run the top level JBossTS ant build:  ant jts
  2) Run the tests:  ant -f run-tests.xml

  For general tests plus JDBC (e.g. use on hudson):
    cd qa
    ant get.drivers dist
    ant -f run-tests.xml junit junit-jdbc

  Paths are relative to the JVM's working dir - don't expect to be able to execute this from anywhere but 'qa'.

-->
<project name="QA Tests for JBossTS" default="junit" basedir=".">
  <!-- set this property to the location of a JBossTS core build -->
  <property name="org.jboss.jbossts.qa.ts.home" location="dist"/>
  <property name="narayana.version" value="5.0.0.M1-SNAPSHOT"/>
  <property name="working.dir" location="build"/>
  <!-- handy utility space where you can copy one or more test groups if you want to run something ad-hoc -->
  <target name="scratch">
    <junit-tests tests="defaulttimeout"/>
    <!--<param name="additional.elements="org.jboss.jbossts.qa.junit.ExecutionWrapper"/>-->
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <!-- a faster subset of the tests for smoke testing. aim to keep to under one hour total. -->
  <target name="express">
    <!-- currenttests01 : 36 tests, 3 minutes -->
    <junit-tests tests="currenttests01"/>
    <!-- jtatests01 : 6 tests, 1 minute -->
    <junit-tests tests="jtatests01"/>
    <!-- otsserver : 20 tests, 7 minutes -->
    <junit-tests tests="otsserver"/>
    <!-- rawresources01_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawresources01_1"/>
    <!-- rawresources02_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawresources02_1"/>
    <!-- rawsubtransactionawareresources01_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawsubtransactionawareresources01_1"/>
    <!-- rawsubtransactionawareresources02_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawsubtransactionawareresources02_1"/>
    <!-- crashrecovery01 : 24 tests, 3 minutes -->
    <junit-tests tests="crashrecovery01"/>
    <!-- crashrecovery02_1 : 5 tests, 6 minutes -->
    <junit-tests tests="crashrecovery02_1"/>
    <!-- crashrecovery03 : 1 tests, 1 minute -->
    <junit-tests tests="crashrecovery03"/>
    <!-- crashrecovery06 : 2 tests, 1 minute -->
    <junit-tests tests="crashrecovery06"/>
    <!-- crashrecovery12 : 7 tests, 5 minutes -->
    <junit-tests tests="crashrecovery12"/>
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <target name="ci-tests" depends="junit-testsuite,junit-jdbc-ncl-testsuite">
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <!-- General tests.
        These tests should take a combined time of around 2h20m or so.
    -->
  <target name="junit" depends="junit-testsuite">
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <target name="junit-testsuite">
    <!-- txcore : 28 tests, 2 minutes -->
    <junit-tests tests="txcore" additional.elements="-DCoordinatorEnvironmentBean.enableStatistics=true"/>
    <!-- txcore_lockrecord : 112 tests, 3 minutes -->
    <junit-tests tests="txcore_lockrecord"/>
    <!-- txcore_abstractrecord : 32 tests, 1 minute -->
    <junit-tests tests="txcore_abstractrecord"/>
    <!-- txcore_statemanager : 64 tests, 2 minutes -->
    <junit-tests tests="txcore_statemanager"/>
    <!-- txcore_utility : 40 tests, 1 minute -->
    <junit-tests tests="txcore_utility"/>
    <!-- txcore_recovery : 36 tests, 4 minutes -->
    <junit-tests tests="txcore_recovery"/>
    <!-- currenttests01 : 36 tests, 2 minutes -->
    <junit-tests tests="currenttests01"/>
    <!-- jtatests01 : 6 tests, 1 minute -->
    <junit-tests tests="jtatests01"/>
    <!-- otsserver : 20 tests, 4 minutes -->
    <junit-tests tests="otsserver"/>
    <!-- jtsremote : 9 tests, 3 minutes -->
    <junit-tests tests="jtsremote"/>
    <!-- defaulttimeout : 2 tests, 2 minutes -->
    <junit-tests tests="defaulttimeout"/>
    <!-- rawresources01_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawresources01_1"/>
    <!-- rawresources01_2 : 147 tests, 7 minutes -->
    <junit-tests tests="rawresources01_2"/>
    <!-- rawresources01_2b : 147 tests, 6 minutes -->
    <junit-tests tests="rawresources01_2b"/>
    <!-- rawresources01_3 : 150 tests, 8 minutes -->
    <junit-tests tests="rawresources01_3"/>
    <!-- rawresources02_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawresources02_1"/>
    <!-- rawresources02_2 : 147 tests, 7 minutes -->
    <junit-tests tests="rawresources02_2"/>
    <!-- rawresources02_2 : 147 tests, 6 minutes -->
    <junit-tests tests="rawresources02_2b"/>
    <!-- rawresources02_3 : 150 tests, 8 minutes -->
    <junit-tests tests="rawresources02_3"/>
    <!-- rawsubtransactionawareresources01_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawsubtransactionawareresources01_1"/>
    <!-- rawsubtransactionawareresources01_2 : 10 tests, 1 minute -->
    <junit-tests tests="rawsubtransactionawareresources01_2"/>
    <!-- rawsubtransactionawareresources01_3 : 25 tests, 2 minutes -->
    <junit-tests tests="rawsubtransactionawareresources01_3"/>
    <!-- rawsubtransactionawareresources02_1 : 6 tests, 1 minute -->
    <junit-tests tests="rawsubtransactionawareresources02_1"/>
    <!-- rawsubtransactionawareresources02_2 : 10 tests, 1 minute -->
    <junit-tests tests="rawsubtransactionawareresources02_2"/>
    <!-- rawsubtransactionawareresources02_3 : 25 tests, 2 minutes -->
    <junit-tests tests="rawsubtransactionawareresources02_3"/>
    <!-- crashrecovery01 : 24 tests, 3 minutes -->
    <junit-tests tests="crashrecovery01"/>
    <!-- crashrecovery02_1 : 5 tests, 2 minutes -->
    <junit-tests tests="crashrecovery02_1"/>
    <!-- crashrecovery02_2 : 50 tests, 12 minutes -->
    <junit-tests tests="crashrecovery02_2"/>
    <!-- crashrecovery03 : 1 tests, 1 minute -->
    <junit-tests tests="crashrecovery03"/>
    <!-- crashrecovery04 : 48 tests, 6 minutes -->
    <junit-tests tests="crashrecovery04"/>
    <!-- crashrecovery05_1 : 10 tests, 3 minutes -->
    <junit-tests tests="crashrecovery05_1"/>
    <!-- crashrecovery05_2 : 100 tests, 25 minutes -->
    <junit-tests tests="crashrecovery05_2"/>
    <!-- crashrecovery06 : 2 tests, 1 minute -->
    <junit-tests tests="crashrecovery06"/>
    <!-- crashrecovery07 : 16 tests, 4 minutes -->
    <junit-tests tests="crashrecovery07"/>
    <!-- crashrecovery08 : 32 tests, 15 minutes -->
    <junit-tests tests="crashrecovery08"/>
    <!-- crashrecovery09 : 6 tests, 2 minutes -->
    <junit-tests tests="crashrecovery09"/>
    <!-- crashrecovery10 : 6 tests, 2 minutes -->
    <junit-tests tests="crashrecovery10"/>
    <!-- crashrecovery12 : 7 tests, 2 minutes -->
    <junit-tests tests="crashrecovery12"/>
  </target>
  <!-- copy the selected db driver out of the available set into the classpath.
        See also build.xml get.drivers and TaskImpl.properties for classpath
     -->
  <macrodef name="install-dbdriver">
    <attribute name="files"/>
    <sequential>
      <delete dir="dbdrivers/selected_dbdriver"/>
      <mkdir dir="dbdrivers/selected_dbdriver"/>
      <copy todir="dbdrivers/selected_dbdriver" flatten="true">
        <fileset dir="dbdrivers/" includes="**/@{files}"/>
      </copy>
    </sequential>
  </macrodef>
  <!--  JDBC tests.
        You'll need a qa/config/jdbc_profiles/<hostname>/JDBCProfiles file for your machine to run these ones,
          although using the 'default' one is also an option.
        Plus copies of the db drivers of course (try 'ant get.drivers' if inside the redhat network).
        And a set of servers to run against. Did I mention it was complicated :-)
    -->
  <target name="junit-jdbc" depends="junit-jdbc-testsuite">
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <target name="junit-jdbc-testsuite">
    <install-dbdriver files="ojdbc14.jar"/>
    <junit-tests tests="jdbcresources01_oracle_thin_jndi"/>
    <junit-tests tests="jdbcresources02_oracle_thin_jndi"/>
    <!-- mssql needs different .jar for jdk 1.5 vs. 1.6 runtime -->
    <condition property="mssql.driver" value="sqljdbc4.jar">
      <equals arg1="${java.specification.version}" arg2="1.6"/>
    </condition>
    <property name="mssql.driver" value="sqljdbc.jar"/>
    <install-dbdriver files="${mssql.driver}"/>
    <junit-tests tests="jdbcresources01_mssqlserver_jndi"/>
    <junit-tests tests="jdbcresources02_mssqlserver_jndi"/>
    <install-dbdriver files="postgresql-8.3-605.jdbc4.jar"/>
    <junit-tests tests="jdbcresources01_pgsql_jndi"/>
    <junit-tests tests="jdbcresources02_pgsql_jndi"/>
    <install-dbdriver files="mysql-connector-java-5.1.8-bin.jar"/>
    <junit-tests tests="jdbcresources01_mysql_jndi"/>
    <junit-tests tests="jdbcresources02_mysql_jndi"/>
    <install-dbdriver files="jconn3.jar"/>
    <junit-tests tests="jdbcresources01_sybase_jndi"/>
    <junit-tests tests="jdbcresources02_sybase_jndi"/>
    <install-dbdriver files="db2*"/>
    <junit-tests tests="jdbcresources01_ibmdb2_jndi"/>
    <junit-tests tests="jdbcresources02_ibmdb2_jndi"/>
  </target>
  <target name="junit-jdbc-ncl" depends="junit-jdbc-ncl-testsuite">
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <!-- the ncl office build server is not on vpn and only a subset of the dbs are available locally -->
  <target name="junit-jdbc-ncl-testsuite">
    <install-dbdriver files="ojdbc14.jar"/>
    <junit-tests tests="jdbcresources01_oracle_thin_jndi"/>
    <junit-tests tests="jdbcresources02_oracle_thin_jndi"/>
    <install-dbdriver files="mysql-connector-java-5.1.8-bin.jar"/>
    <junit-tests tests="jdbcresources01_mysql_jndi"/>
    <junit-tests tests="jdbcresources02_mysql_jndi"/>
    <install-dbdriver files="postgresql-8.3-605.jdbc4.jar"/>
    <junit-tests tests="jdbcresources01_pgsql_jndi"/>
    <junit-tests tests="jdbcresources02_pgsql_jndi"/>
  </target>
  <target name="junit-jdbc-crachrec">
    <!-- crashrecovery11 : jdbc resource crash recovery tests. 4 tests, 4 minutes per db -->
    <install-dbdriver files="ojdbc14.jar"/>
    <junit-tests tests="crashrecovery11-oracle_jndi"/>
    <!--mssql needs different .jar for jdk 1.5 vs. 1.6 runtime -->
    <condition property="mssql.driver" value="sqljdbc4.jar">
      <equals arg1="${java.specification.version}" arg2="1.6"/>
    </condition>
    <property name="mssql.driver" value="sqljdbc.jar"/>
    <install-dbdriver files="${mssql.driver}"/>
    <junit-tests tests="crashrecovery11-mssqlserver_jndi"/>
    <install-dbdriver files="db2*"/>
    <junit-tests tests="crashrecovery11-ibmdb2_jndi"/>
    <install-dbdriver files="postgresql-8.3-603.jdbc3.jar"/>
    <junit-tests tests="crashrecovery11-pgsql_jndi"/>
    <install-dbdriver files="mysql-connector-java-5.1.7-bin.jar"/>
    <junit-tests tests="crashrecovery11-mysql_jndi"/>
    <install-dbdriver files="jconn3.jar"/>
    <junit-tests tests="crashrecovery11-sybase_jndi"/>
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <target name="jta">
    <!-- override the config file, so that we can run jta mode tests even with jts binaries -->
    <property name="additional.elements" value="-Dcom.arjuna.ats.arjuna.common.propertiesFile=../ArjunaJTA/narayana-jta/src/main/resources/jbossts-properties.xml"/>
    <!-- txcore : 28 tests, 2 minutes -->
    <junit-tests tests="txcore" additional.elements="-DCoordinatorEnvironmentBean.enableStatistics=true"/>
    <!-- txcore_lockrecord : 112 tests, 3 minutes -->
    <junit-tests tests="txcore_lockrecord"/>
    <!-- txcore_abstractrecord : 32 tests, 1 minute -->
    <junit-tests tests="txcore_abstractrecord"/>
    <!-- txcore_statemanager : 64 tests, 2 minutes -->
    <junit-tests tests="txcore_statemanager"/>
    <!-- txcore_utility : 40 tests, 1 minute -->
    <junit-tests tests="txcore_utility"/>
    <!-- jtatest01 : 6 tests, minute-->
    <junit-tests tests="jtatests01"/>
    <!-- jdbclocals01 : 6 tests, 2 minutes for each db -->
    <install-dbdriver files="ojdbc14.jar"/>
    <junit-tests tests="jdbclocals01_oracle_jndi"/>
    <!-- mssql needs different .jar for jdk 1.5 vs. 1.6 runtime -->
    <condition property="mssql.driver" value="sqljdbc4.jar">
      <equals arg1="${java.specification.version}" arg2="1.6"/>
    </condition>
    <property name="mssql.driver" value="sqljdbc.jar"/>
    <install-dbdriver files="${mssql.driver}"/>
    <junit-tests tests="jdbclocals01_mssqlserver_jndi"/>
    <install-dbdriver files="postgresql-8.3-603.jdbc3.jar"/>
    <junit-tests tests="jdbclocals01_pgsql_jndi"/>
    <install-dbdriver files="mysql-connector-java-5.1.7-bin.jar"/>
    <junit-tests tests="jdbclocals01_mysql_jndi"/>
    <install-dbdriver files="jconn3.jar"/>
    <junit-tests tests="jdbclocals01_sybase_jndi"/>
    <install-dbdriver files="db2*"/>
    <junit-tests tests="jdbclocals01_ibmdb2_jndi"/>
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <target name="performance">
    <!-- caution: perf tests are essentially regression tests and are only meaningful
            if used with the same hardware (profile) and config between runs. -->
    <!-- perfprofileio : 18 tests, 9 minutes -->
    <junit-tests tests="perfprofileio"/>
    <!-- perfprofile01_i (JTS implicit) : 25 tests, 31 minutes -->
    <junit-tests tests="perfprofile01_i"/>
    <!-- perfprofile01_e (JTS explicit) : 25 tests, 35 minutes -->
    <junit-tests tests="perfprofile01_e"/>
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <target name="core-memory">
    <!-- txcore_memory : 40 tests -->
    <junit-tests tests="txcore_memory"/>
    <!-- you need the right .so for the platform the test runs on. Note the the jvm
            may print 'can't find agent lib' when it can find one but it's the wrong one.
              ext/libjbossAgent_linux64.so : Fedora 12, x86_64  additional.elements="-agentpath:ext/libjbossAgent_linux64.so"/> -->
              
    <fail if="failed-tests" message="some tests failed"/>
  </target>
  <!-- ##################################### -->
  <!-- This is where all the hard work happens - use junit to coordinate multi-process tests: -->
  <macrodef name="junit-tests">
    <attribute name="tests"/>
    <!-- pass in param to override this. By default, the TaskImpl.properties are not modified -->
    <!--<property name="additional.elements="org.jboss.jbossts.qa.junit.ExecutionWrapper"/>-->
    <attribute name="additional.elements" default=""/>
    <sequential>
      <!-- TODO support JTA mode testing of JTS .jar files? -
            would need classpath munging for props file in TaskImpl.properties -->
      <echo message="Running junit test group @{tests} from basedir=${basedir}"/>
      <!-- this runs forked because the product config file it uses has relative paths in it, so we need to guarantee
            the working dir is the same as the location of this script. -->
      <junit printsummary="yes" haltonfailure="no" fork="true" dir="${basedir}" showoutput="false" errorproperty="failed-tests">
        <classpath>
          <!--
                This is the classpath for the test framework, not the test components e.g. clients/servers.
                Those are configured via TaskImpl.properties instead.

                The test groups (org.jboss.jbossts.qa.junit.testgroup.TestGroup_XXXX classes) contains the
                test methods, which link against the test classes, which in turn link against JBossTS.
                Hence we need JBossTS in the classpath for the framework, even though it does not get run there.
                On the up side, you get better diagnostic messages and code management/navigation in IDEs.
                -->
          <pathelement location="ext/junit.jar"/>
          <fileset dir="tests/build">
            <include name="jbossts-*-qa.jar"/>
          </fileset>
          <fileset dir="${org.jboss.jbossts.qa.ts.home}/narayana-full-${narayana.version}/lib">
            <include name="*.jar"/>
          </fileset>
          <fileset dir="${org.jboss.jbossts.qa.ts.home}/narayana-full-${narayana.version}/lib/ext">
            <include name="*.jar"/>
            <include name="*.zip"/>
          </fileset>
          <!-- Commented out as this is just running the same tests again?
        <fileset dir="../ArjunaJTS/jts/build/lib">
          <include name="jts_tests.jar"/>
        </fileset> 
        -->
          <pathelement location="${org.jboss.jbossts.qa.ts.home}/narayana-full-${narayana.version}/etc"/>
        </classpath>
        <formatter type="plain"/>
        <test name="org.jboss.jbossts.qa.junit.testgroup.TestGroup_@{tests}"/>
        <sysproperty key="names" value=".*"/>
        <sysproperty key="additional.elements" value="@{additional.elements}"/>
        <!--<jvmarg value="-Xdebug"/>-->
        <!--<jvmarg value="-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5007"/>-->
      </junit>
    </sequential>
  </macrodef>
  <!-- directory that contains emma.jar and emma_ant.jar: -->
  <path id="emma.lib">
    <pathelement location="../ext/emma.jar"/>
    <pathelement location="ext/emma_ant.jar"/>
  </path>
  <taskdef resource="emma_ant.properties" classpathref="emma.lib"/>
  <target name="emmareport">
    <emma enabled="true">
      <report>
        <fileset dir="..">
          <include name="**/target/**/metadata.emma"/>
        </fileset>
        <fileset dir="testoutput">
          <include name="**/*-coverage.ec"/>
        </fileset>
        <fileset dir="..">
          <include name="**/target/**/coverage.ec"/>
        </fileset>
        <sourcepath>
          <dirset dir="..">
            <include name="**/classes"/>
          </dirset>
        </sourcepath>
        <txt outfile="testoutput/emma/coverage.txt"/>
        <html outfile="testoutput/emma/coverage.html"/>
      </report>
    </emma>
  </target>
  <!--

    unused groups, pending cleanup and wiring:

    ait01_ots_transactionmanager.java
    aitresources01.java
    crashrecovery13.java

    jdbcresources03_oracle_thin_jndi.java
    jdbcresources04_oracle_thin_jndi.java

    txoj.java - thse should be unit tests.

    -->
</project>
